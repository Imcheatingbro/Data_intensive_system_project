{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629c7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成完毕，已保存到 D:/Data_intensive_system_project/Data\\5.csv\n",
      "程序运行时间为 1834.08 秒\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Part 1:Data generation\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import time  # 用于记录时间\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 生成随机时间函数\n",
    "def random_time(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# 生成部分数据集的函数，每个线程执行这个函数\n",
    "def generate_partial_data(num_clients, num_calls, thread_id, used_pairs, output_dir):\n",
    "    clients = list(range(1, num_clients + 1))  # 客户ID从1开始\n",
    "    start_date = datetime(year=2024, month=1, day=1)\n",
    "    end_date = datetime(year=2024, month=12, day=31)\n",
    "\n",
    "    # 临时文件名使用线程ID来区分，保存到指定目录\n",
    "    partial_filename = os.path.join(output_dir, f'temp_data_part_{thread_id}.csv')\n",
    "    \n",
    "    with open(partial_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for _ in range(num_calls):\n",
    "            while True:\n",
    "                client1 = random.choice(clients)\n",
    "                client2 = random.choice(clients)\n",
    "                if client1 != client2:\n",
    "                    # 使用frozenset确保客户顺序无关\n",
    "                    pair = frozenset([client1, client2])\n",
    "                    if pair not in used_pairs:\n",
    "                        used_pairs.add(pair)  # 记录该对已经使用\n",
    "                        break\n",
    "\n",
    "            # 随机生成开始时间和持续时间（1分钟到300分钟）\n",
    "            start_time = random_time(start_date, end_date)\n",
    "            duration_minutes = random.randint(1, 300)  # 通话持续时间随机为1到300分钟\n",
    "            end_time = start_time + timedelta(minutes=duration_minutes)\n",
    "\n",
    "            # 转换为所需的时间格式 YYMMDDHHMM\n",
    "            start_str = start_time.strftime(\"%y%m%d%H%M\")\n",
    "            end_str = end_time.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "            # 逐条写入CSV文件\n",
    "            writer.writerow([client1, client2, start_str, end_str])\n",
    "\n",
    "    return partial_filename\n",
    "\n",
    "# 主函数：使用多线程生成完整数据集\n",
    "def generate_synthetic_calls_multithreaded(num_clients, total_num_calls, num_threads, output_dir, output_filename):\n",
    "    calls_per_thread = total_num_calls // num_threads\n",
    "    used_pairs = set()  # 存储已经生成过的客户对（无序）\n",
    "\n",
    "    # 检查输出目录是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 记录开始时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 创建一个线程池，并行生成数据\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for i in range(num_threads):\n",
    "            futures.append(executor.submit(generate_partial_data, num_clients, calls_per_thread, i, used_pairs, output_dir))\n",
    "        \n",
    "        # 收集所有生成的临时文件\n",
    "        partial_files = [future.result() for future in futures]\n",
    "\n",
    "    # 使用用户指定的文件名保存最终输出文件\n",
    "    output_file = os.path.join(output_dir, output_filename)\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        #writer.writerow(['Client1', 'Client2', 'Start_Time', 'End_Time'])  # 添加表头\n",
    "        for partial_file in partial_files:\n",
    "            with open(partial_file, 'r') as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    # 删除临时文件\n",
    "    for partial_file in partial_files:\n",
    "        os.remove(partial_file)\n",
    "\n",
    "    # 记录结束时间\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 计算并输出运行时间\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"数据生成完毕，已保存到 {output_file}\")\n",
    "    print(f\"程序运行时间为 {total_time:.2f} 秒\")\n",
    "\n",
    "# 调用函数生成数据集，指定输出路径和文件名\n",
    "generate_synthetic_calls_multithreaded(\n",
    "    num_clients=800000, \n",
    "    total_num_calls=100000000, \n",
    "    num_threads=24, \n",
    "    output_dir=\"D:/Data_intensive_system_project/Data\", \n",
    "    output_filename=\"5.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成完毕，已保存到 D:/Data_intensive_system_project/Data\\final_data.parquet\n",
      "程序运行时间为 833.39 秒\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time  # 用于记录时间\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "# 生成随机时间函数\n",
    "def random_time(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# 生成部分数据集的函数，每个线程执行这个函数\n",
    "def generate_partial_data(num_clients, num_calls, thread_id, used_pairs, output_dir):\n",
    "    clients = list(range(1, num_clients + 1))  # 客户ID从1开始\n",
    "    start_date = datetime(year=2024, month=1, day=1)\n",
    "    end_date = datetime(year=2024, month=12, day=31)\n",
    "\n",
    "    # 存储数据的列表\n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_calls):\n",
    "        while True:\n",
    "            client1 = random.choice(clients)\n",
    "            client2 = random.choice(clients)\n",
    "            if client1 != client2:\n",
    "                # 使用frozenset确保客户顺序无关\n",
    "                pair = frozenset([client1, client2])\n",
    "                if pair not in used_pairs:\n",
    "                    used_pairs.add(pair)  # 记录该对已经使用\n",
    "                    break\n",
    "\n",
    "        # 随机生成开始时间和持续时间（1分钟到300分钟）\n",
    "        start_time = random_time(start_date, end_date)\n",
    "        duration_minutes = random.randint(1, 300)  # 通话持续时间随机为1到300分钟\n",
    "        end_time = start_time + timedelta(minutes=duration_minutes)\n",
    "\n",
    "        # 转换为所需的时间格式 YYMMDDHHMM\n",
    "        start_str = start_time.strftime(\"%y%m%d%H%M\")\n",
    "        end_str = end_time.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "        # 将数据加入列表\n",
    "        data.append([client1, client2, start_str, end_str])\n",
    "\n",
    "    # 将数据转换为 pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"client1\", \"client2\", \"start_time\", \"end_time\"])\n",
    "\n",
    "    # 将 DataFrame 保存为 Parquet 文件\n",
    "    partial_filename = os.path.join(output_dir, f'temp_data_part_{thread_id}.parquet')\n",
    "    df.to_parquet(partial_filename, index=False)\n",
    "\n",
    "    return partial_filename\n",
    "\n",
    "# 主函数：使用多线程生成完整数据集\n",
    "def generate_synthetic_calls_multithreaded(num_clients, total_num_calls, num_threads, output_dir, output_filename):\n",
    "    calls_per_thread = total_num_calls // num_threads\n",
    "    used_pairs = set()  # 存储已经生成过的客户对（无序）\n",
    "\n",
    "    # 检查输出目录是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 记录开始时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 创建一个线程池，并行生成数据\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for i in range(num_threads):\n",
    "            futures.append(executor.submit(generate_partial_data, num_clients, calls_per_thread, i, used_pairs, output_dir))\n",
    "        \n",
    "        # 收集所有生成的临时文件\n",
    "        partial_files = [future.result() for future in futures]\n",
    "\n",
    "    # 合并所有临时文件为一个完整的Parquet文件\n",
    "    dataframes = []\n",
    "    for partial_file in partial_files:\n",
    "        df = pd.read_parquet(partial_file)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # 合并所有的 DataFrame\n",
    "    final_df = pd.concat(dataframes)\n",
    "\n",
    "    # 将合并的数据保存为最终的 Parquet 文件\n",
    "    output_file = os.path.join(output_dir, output_filename)\n",
    "    final_df.to_parquet(output_file, index=False)\n",
    "\n",
    "    # 删除临时文件\n",
    "    for partial_file in partial_files:\n",
    "        os.remove(partial_file)\n",
    "\n",
    "    # 记录结束时间\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 计算并输出运行时间\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"数据生成完毕，已保存到 {output_file}\")\n",
    "    print(f\"程序运行时间为 {total_time:.2f} 秒\")\n",
    "\n",
    "# 调用函数生成数据集，指定输出路径和文件名\n",
    "generate_synthetic_calls_multithreaded(\n",
    "    num_clients=1000000, \n",
    "    total_num_calls=100000000, \n",
    "    num_threads=32, \n",
    "    output_dir=\"D:/Data_intensive_system_project/Data\", \n",
    "    output_filename=\"final_data.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a5e2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\Data_intensive_system\\python.exe\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c20abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_intensive_system",
   "language": "python",
   "name": "data_intensive_system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
